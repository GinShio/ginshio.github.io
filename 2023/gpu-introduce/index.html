

<!DOCTYPE html>
<html lang="zh-cn">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="robots" content="noodp" />
    <title>GPU 基础介绍 - iris</title><meta name="Description" content="GinShio | Introduce to GPU"><meta property="og:url" content="https://blog.ginshio.org/2023/gpu-introduce/">
  <meta property="og:site_name" content="iris">
  <meta property="og:title" content="GPU 基础介绍">
  <meta property="og:description" content="GinShio | Introduce to GPU">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-08-28T22:25:22+08:00">
    <meta property="article:modified_time" content="2023-09-01T19:16:42+08:00">
    <meta property="article:tag" content="Introduce">
    <meta property="article:tag" content="AMD">
    <meta property="og:image" content="https://blog.ginshio.org/avatar.webp">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://blog.ginshio.org/avatar.webp">
  <meta name="twitter:title" content="GPU 基础介绍">
  <meta name="twitter:description" content="GinShio | Introduce to GPU">
<meta name="application-name" content="iris">
<meta name="apple-mobile-web-app-title" content="iris">

<meta name="theme-color" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://blog.ginshio.org/2023/gpu-introduce/" /><link rel="prev" href="https://blog.ginshio.org/2023/how-to-build-mesa/" /><link rel="next" href="https://blog.ginshio.org/2024/how-to-use-deqp-runner/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.1d6e6517c44074bf1c692657d249d106a5e98bb9db25f7773715b24eda7aa575354611c095c23092aa17916f1b5be527.css" integrity="sha384-HW5lF8RAdL8caSZX0knRBqXpi7nbJfd3NxWyTtp6pXU1RhHAlcIwkqoXkW8bW&#43;Un"><link rel="stylesheet" href="/css/color.34e5eb0ed3195c558eb6994b94f6ce01b4d7121bda08365c4f94b70d178301efdb761cb63c963c02c67c45152c3c9498.css" integrity="sha384-NOXrDtMZXFWOtplLlPbOAbTXEhvaCDZcT5S3DReDAe/bdhy2PJY8AsZ8RRUsPJSY"><link rel="stylesheet" href="/css/style.min.71903c93e482438bcb694a21934b32795f3f9dc2c7076dadfa66ca836805f90335eae546d168ddaa1c5de8eda3532d79.css" integrity="sha384-cZA8k&#43;SCQ4vLaUohk0syeV8/ncLHB22t&#43;mbKg2gF&#43;QM16uVG0Wjdqhxd6O2jUy15"><link rel="preload" as="style" onload="this.onload=null;this.rel='stylesheet'" href="/lib/fontawesome-free/all.min.2cba216129d7b04299cad0e4a8bb0eb317de61d6e2489778de53950bfcb59fa58d01a258c9e2675ffa3c07c058996f2d.css" integrity="sha384-LLohYSnXsEKZytDkqLsOsxfeYdbiSJd43lOVC/y1n6WNAaJYyeJnX/o8B8BYmW8t">
        <noscript><link rel="stylesheet" href="/lib/fontawesome-free/all.min.2cba216129d7b04299cad0e4a8bb0eb317de61d6e2489778de53950bfcb59fa58d01a258c9e2675ffa3c07c058996f2d.css" integrity="sha384-LLohYSnXsEKZytDkqLsOsxfeYdbiSJd43lOVC/y1n6WNAaJYyeJnX/o8B8BYmW8t"></noscript><link rel="preload" as="style" onload="this.onload=null;this.rel='stylesheet'" href="/lib/animate/animate.min.1aedca555d87f5dfb2038403a5507b55c3b284994056b717774b61123af82b39df6853cb7b4c50272a2757138d6b8642.css" integrity="sha384-Gu3KVV2H9d&#43;yA4QDpVB7VcOyhJlAVrcXd0thEjr4KznfaFPLe0xQJyonVxONa4ZC">
        <noscript><link rel="stylesheet" href="/lib/animate/animate.min.1aedca555d87f5dfb2038403a5507b55c3b284994056b717774b61123af82b39df6853cb7b4c50272a2757138d6b8642.css" integrity="sha384-Gu3KVV2H9d&#43;yA4QDpVB7VcOyhJlAVrcXd0thEjr4KznfaFPLe0xQJyonVxONa4ZC"></noscript>
    
    
    
    <meta name="google-site-verification" content="fbzw9fQcZyEFrrrUtxLfzYW-qhZ5TMEZKHHSp9NeLBw" /><meta name="msvalidate.01" content="EC9CEC799D42793C414AE7BDB0D0205C" /><meta name="yandex-verification" content="c0b808dd3e49f730" /><meta name="baidu-site-verification" content="code-RhPhu2ccLc" /><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "GPU 基础介绍",
        "inLanguage": "zh-cn",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/blog.ginshio.org\/2023\/gpu-introduce\/"
        },"image": ["https:\/\/blog.ginshio.org\/screenshot.png"],"genre": "posts","keywords": "Introduce, AMD","wordcount":  1962 ,
        "url": "https:\/\/blog.ginshio.org\/2023\/gpu-introduce\/","datePublished": "2023-08-28T22:25:22+08:00","dateModified": "2023-09-01T19:16:42+08:00","publisher": {
            "@type": "Organization",
            "name": "GinShio","logo": "https:\/\/blog.ginshio.org\/avatar.webp"},"authors": [{
                        "@type": "Person",
                        "name": "GinShio"                    
                    }],"description": "GinShio | Introduce to GPU"
    }
    </script><script src="//instant.page/5.1.1" defer type="module" integrity="sha384-MWfCL6g1OTGsbSwfuMHc8+8J2u71/LA8dzlIN3ycajckxuZZmF+DNjdm7O6H3PSq"></script>
</head>

<body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">
        function setTheme(theme) {document.body.setAttribute('theme', theme); document.documentElement.style.setProperty('color-scheme', theme === 'light' ? 'light' : 'dark'); window.theme = theme; }
        function saveTheme(theme) {window.localStorage && localStorage.setItem('theme', theme);}
        function getMeta(metaName) {const metas = document.getElementsByTagName('meta'); for (let i = 0; i < metas.length; i++) if (metas[i].getAttribute('name') === metaName) return metas[i]; return '';}
        if (window.localStorage && localStorage.getItem('theme')) {let theme = localStorage.getItem('theme');theme === 'light' || theme === 'dark' || theme === 'black' ? setTheme(theme) : (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches ? setTheme('dark') : setTheme('light')); } else { if ('light' === 'light' || 'light' === 'dark' || 'light' === 'black') setTheme('light'), saveTheme('light'); else saveTheme('auto'), window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches ? setTheme('dark') : setTheme('light');}
        let metaColors = {'light': '#f8f8f8','dark': '#252627','black': '#000000'}
        getMeta('theme-color').content = metaColors[document.body.getAttribute('theme')];
    </script>
    <div id="back-to-top"></div>
    <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="iris"><span class="header-title-pre"><i class="fas fa-terminal"></i></span>iris</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"><i class="fa fa-archive faa-wrench"></i> 归档 </a><a class="menu-item" href="/tags/"><i class="fa fa-tag faa-wrench"></i> 标签 </a><a class="menu-item" href="/categories/"><i class="fa fa-folder-open faa-wrench"></i> 分类 </a><a class="menu-item" href="/series/"><i class="fas fa-object-group"></i> 系列 </a><a class="menu-item" href="/about/"><i class="fa fa-info-circle faa-wrench"></i> 关于 </a><a class="menu-item" href="/links/"><i class="fa fa-user-friends faa-wrench"></i> 友人帐 </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-desktop">
                        <a href="#" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="#" class="search-button search-clear" id="search-clear-desktop" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="#" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="iris"><span class="header-title-pre"><i class="fas fa-terminal"></i></span>iris</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-mobile">
                        <a href="#" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="#" class="search-button search-clear" id="search-clear-mobile" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="#" class="search-cancel" id="search-cancel-mobile">
                        取消
                    </a>
                </div><a class="menu-item" href="/posts/" title=""><i class="fa fa-archive faa-wrench"></i>归档</a><a class="menu-item" href="/tags/" title=""><i class="fa fa-tag faa-wrench"></i>标签</a><a class="menu-item" href="/categories/" title=""><i class="fa fa-folder-open faa-wrench"></i>分类</a><a class="menu-item" href="/series/" title=""><i class="fas fa-object-group"></i>系列</a><a class="menu-item" href="/about/" title=""><i class="fa fa-info-circle faa-wrench"></i>关于</a><a class="menu-item" href="/links/" title=""><i class="fa fa-user-friends faa-wrench"></i>友人帐</a><a href="#" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
            <div class="container"><div class="toc" id="toc-auto">
        <h2 class="toc-title">目录</h2>
        <div class="toc-content" id="toc-content-auto"><nav id="TableOfContents">
  <ul>
    <li><a href="#gpgpu-模型简介">GPGPU 模型简介</a>
      <ul>
        <li><a href="#simt-模型">SIMT 模型</a></li>
        <li><a href="#寄存器">寄存器</a>
          <ul>
            <li><a href="#vgpr">VGPR</a></li>
            <li><a href="#sgpr">SGPR</a></li>
            <li><a href="#alignment-与-bank">Alignment 与 Bank</a></li>
          </ul>
        </li>
        <li><a href="#控制流">控制流</a>
          <ul>
            <li><a href="#divergent-与-convergent">Divergent 与 Convergent</a></li>
            <li><a href="#waterfall-loop">Waterfall Loop</a></li>
            <li><a href="#线性控制流">线性控制流</a></li>
          </ul>
        </li>
        <li><a href="#共享内存">共享内存</a></li>
        <li><a href="#缓存">缓存</a>
          <ul>
            <li><a href="#分级缓存">分级缓存</a></li>
            <li><a href="#访存优化">访存优化</a></li>
            <li><a href="#缓存控制">缓存控制</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#体系结构">体系结构</a>
      <ul>
        <li><a href="#指令流水线--instruction-pipelining">指令流水线 (Instruction Pipelining)</a></li>
        <li><a href="#数据冒险">数据冒险</a></li>
        <li><a href="#sopp-指令">SOPP 指令</a>
          <ul>
            <li><a href="#s-delay-alu">S_DELAY_ALU</a></li>
            <li><a href="#s-waitcnt">S_WAITCNT</a></li>
          </ul>
        </li>
        <li><a href="#分支预测">分支预测</a></li>
        <li><a href="#指令预取">指令预取</a></li>
      </ul>
    </li>
    <li><a href="#gpgpu--general-purpose-computing-on-graphics-processing-units">GPGPU (General-purpose computing on graphics processing units)</a>
      <ul>
        <li><a href="#workgroup-与-subgroup">Workgroup 与 Subgroup</a>
          <ul>
            <li><a href="#线程标识">线程标识</a></li>
            <li><a href="#线程标识的实现">线程标识的实现</a></li>
            <li><a href="#subgroup-操作">Subgroup 操作</a></li>
          </ul>
        </li>
        <li><a href="#内存模型">内存模型</a></li>
        <li><a href="#ieee-754">IEEE 754</a>
          <ul>
            <li><a href="#浮点数的表示">浮点数的表示</a></li>
            <li><a href="#精度">精度</a></li>
            <li><a href="#float-control">Float Control</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#compiler">Compiler</a></li>
  </ul>
</nav></div>
    </div><script>document.getElementsByTagName("main")[0].setAttribute("autoTOC", "true")</script><article class="page single"><h1 class="single-title animate__animated animate__flipInX">GPU 基础介绍</h1><div class="post-meta">
            <div class="post-meta-line">
                <span class="post-author"><span class='author'><i class="author fas fa-user-circle fa-fw"></i><span class='screen-reader-text'>  </span><a href='https://blog.ginshio.org/authors/ginshio'>GinShio</a></span>
                </span>&nbsp;<span class="post-category">收录于 </span>&nbsp;<span class="post-category">类别 <a href="/categories/gpu/"><i class="far fa-folder fa-fw"></i>GPU</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="08-28">08-28</time>&nbsp;<i class="far fa-edit fa-fw"></i>&nbsp;<time datetime="09-01">09-01</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 1962 字&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 10 分钟&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#gpgpu-模型简介">GPGPU 模型简介</a>
      <ul>
        <li><a href="#simt-模型">SIMT 模型</a></li>
        <li><a href="#寄存器">寄存器</a>
          <ul>
            <li><a href="#vgpr">VGPR</a></li>
            <li><a href="#sgpr">SGPR</a></li>
            <li><a href="#alignment-与-bank">Alignment 与 Bank</a></li>
          </ul>
        </li>
        <li><a href="#控制流">控制流</a>
          <ul>
            <li><a href="#divergent-与-convergent">Divergent 与 Convergent</a></li>
            <li><a href="#waterfall-loop">Waterfall Loop</a></li>
            <li><a href="#线性控制流">线性控制流</a></li>
          </ul>
        </li>
        <li><a href="#共享内存">共享内存</a></li>
        <li><a href="#缓存">缓存</a>
          <ul>
            <li><a href="#分级缓存">分级缓存</a></li>
            <li><a href="#访存优化">访存优化</a></li>
            <li><a href="#缓存控制">缓存控制</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#体系结构">体系结构</a>
      <ul>
        <li><a href="#指令流水线--instruction-pipelining">指令流水线 (Instruction Pipelining)</a></li>
        <li><a href="#数据冒险">数据冒险</a></li>
        <li><a href="#sopp-指令">SOPP 指令</a>
          <ul>
            <li><a href="#s-delay-alu">S_DELAY_ALU</a></li>
            <li><a href="#s-waitcnt">S_WAITCNT</a></li>
          </ul>
        </li>
        <li><a href="#分支预测">分支预测</a></li>
        <li><a href="#指令预取">指令预取</a></li>
      </ul>
    </li>
    <li><a href="#gpgpu--general-purpose-computing-on-graphics-processing-units">GPGPU (General-purpose computing on graphics processing units)</a>
      <ul>
        <li><a href="#workgroup-与-subgroup">Workgroup 与 Subgroup</a>
          <ul>
            <li><a href="#线程标识">线程标识</a></li>
            <li><a href="#线程标识的实现">线程标识的实现</a></li>
            <li><a href="#subgroup-操作">Subgroup 操作</a></li>
          </ul>
        </li>
        <li><a href="#内存模型">内存模型</a></li>
        <li><a href="#ieee-754">IEEE 754</a>
          <ul>
            <li><a href="#浮点数的表示">浮点数的表示</a></li>
            <li><a href="#精度">精度</a></li>
            <li><a href="#float-control">Float Control</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#compiler">Compiler</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p>该篇介绍主要以 AMDGPU 7900XTX (Navi31) 为例。</p>
<h2 id="gpgpu-模型简介" class="headerLink">
    <a href="#gpgpu-%e6%a8%a1%e5%9e%8b%e7%ae%80%e4%bb%8b" class="header-mark"></a>GPGPU 模型简介</h2><figure><img src="/images/AMDGPU_RDNA3_HW_BlockDiagram.png">
</figure>

<h3 id="simt-模型" class="headerLink">
    <a href="#simt-%e6%a8%a1%e5%9e%8b" class="header-mark"></a>SIMT 模型</h3><p>现代 GPU 上基本使用 <strong>SIMT</strong> (单指令多线程, Single Instruction Multiple Threads) 模型，即一条指令执行在多个线程 (thread / lane / invocation) 上，每个线程上可能存储、运算不同地数据，也就是说具有大规模<strong>并行</strong>计算的能力。</p>
<p>在 SIMT 模型上，由于指令是一次性发送到多个线程上，因此需要一个管理线程的单元。在
Vulkan 中将其称其为 <strong>subgroup</strong>，在 DirectX 或 AMDGPU 上被称为 wavefront，Nvidia 将其称之为 wrap。Subgroup 是 GPU 上的最小控制单元，即使我们需要一个线程，我们也只能向 GPU 申请使用一个 subgroup。</p>
<p>AMDGPU 上 subgroup 的最小是 32 个线程 (wave32)，但是可以使用 2 个 wave32 组成一个 wave64 使用。以下无特殊说明，subgroup 以基础的 wave32 介绍。</p>
<p>SIMD 执行单元是一个更大层级的单元，根据 AMDGPU 公开的 RDNA 资料，一个 SIMD 上有
16 个 ALU (算术逻辑单元，Arithmetic logic unit)，也就是 16 个 subgroup。另外一些更上层的控制单元简单地列举：</p>
<ul>
<li>CU (Compute Unit) 包含 2 个 SIMD</li>
<li>WGP (Work-group Processor) 包含 2 个 CU</li>
<li>SA (Shader Array)</li>
<li>SE (Shader Engine)</li>
</ul>
<p>在 AMDGPU 的公开手册 <em>2.3. Work-groups</em> 中详细说明了 CU 与 WGP 的区别。</p>
<h3 id="寄存器" class="headerLink">
    <a href="#%e5%af%84%e5%ad%98%e5%99%a8" class="header-mark"></a>寄存器</h3><p>寄存器是计算机体系中的重要概念，因为只有寄存器可以被 ALU 直接使用，而存储在其他地方的数据，只有先加载进寄存器中才可以使用。另外，寄存器由于是距离 ALU 最近的存储结构，因此也是整个体系结构中存储大小最小，但最高效的存储结构。</p>
<p>在 AMDGPU 上每个寄存器 32 bit，或者称其为 1 DWORD。</p>
<h4 id="vgpr" class="headerLink">
    <a href="#vgpr" class="header-mark"></a>VGPR</h4><p>在 SIMT 模型中介绍了基础结构，比如我们有指令 <code>v0 = add float v1, v2</code>，虽然只使用了
3 个寄存器，实际上在整个 subgroup 上每个线程都需要有这三个寄存器。也就是说，在
subgroup 上至少需要 <code>3*32*4</code> 字节的存储空间。如果 subgroup 设置为 wave64，那么将两个 wave32 的寄存器拼为一个 wave64 所使用的寄存器。</p>
<p>这种寄存器被称之为 <strong>VGPR</strong> (向量通用寄存器，Vector General Purpose Register)，被用于各种 SIMT 运算。这些 VGPR 被存储在一个被称为 <em>Vector Register File</em> 的 SIMD 的私有内存上。</p>
<p>每个 subgroup 最多使用 <strong>256</strong> 个 VGPR，SIMD 上最多有 <strong>1536</strong> 个 VGPR (Navi31)。可以计算出，如果程序使用少于 96 个 VGPR，那么我们可以使用所有的 subgroup。但是当程序使用 256 个 VGPR 时，也就是说最多只有 <em>6</em> 个 subgroup 可以同时运行。</p>
<h4 id="sgpr" class="headerLink">
    <a href="#sgpr" class="header-mark"></a>SGPR</h4><p>如果说我们有一组在 subgroup 上都相同的数据，那么对于它的计算并不需要使用 SIMT 模型。这时候就需要引入 SALU，即一个 subgroup 上每个线程看到的数据和指令都相同的。通常，GPU 上可以认为 Scalar 指令总比 Vector 指令高效。</p>
<p>无论是 wave32 还是 wave64，每个 subgroup 可以使用 106 个 SGPR，以及 22 个特殊
SGPR：</p>
<ul>
<li>106 个通用 SGPR (s0~s105)</li>
<li>VCC_LO 和 VCC_HI (s106, s107)</li>
<li>用于处理 trap 的 16 个 Trap Temporary (TTMP0<del>TTMP15, s108</del>s120)</li>
<li>NULL (s124)</li>
<li>M0 (s125)</li>
<li>EXEC_LO 和 EXEC_HI (s126, s127)</li>
</ul>
<h4 id="alignment-与-bank" class="headerLink">
    <a href="#alignment-%e4%b8%8e-bank" class="header-mark"></a>Alignment 与 Bank</h4><p>VGPR 的使用是按照块分配的，即每个 subgroup 一次最少向 Vector Register File 申请的数量，在 Navi31 上是 24 个 VGPR，这个数字在 wave64 上砍半。</p>
<p>VGPR 有 4 个 bank，当一条指令上的多个 src (源操作数) 来自同一个 bank 时，对于这些数据的加载是阻塞的，我们将其称之为 <strong>Bank Conflict</strong>。也就是说，只有当下一个周期时，指令才可以将下一个源操作数加载进 ALU。</p>
<p>示例：考虑 <code>v0 = mad i32 v0, v1, v3</code> 和 <code>v0 = mad i32 v0, v4, v8</code>。前者只需要一个周期就可以准备好数据，而后者需要三个周期用于准备数据。因为 v0 / v4 / v8 属于同一个
bank。</p>
<p>SGPR 每次读取 8 字节数据，换句话说，SGPR 总是<strong>偶数对齐</strong>的。</p>
<h3 id="控制流" class="headerLink">
    <a href="#%e6%8e%a7%e5%88%b6%e6%b5%81" class="header-mark"></a>控制流</h3><p>无论对于什么编程语言来说，控制流 (Control Flow) 都是一个重要的概念。对于 GPU 来说，控制流是发生在一个 subgroup 上的，因此我们无法精细化地控制每个线程。</p>
<p>当发生分支跳转时，AMDGPU 使用 EXEC 掩码来区分 subgroup 中的哪些线程是需要执行的，而另一些是不需要执行的。因此在 GPU 上，分支是相对高代价的操作，当执行一个分支时，另一部分线程可以被认为是完全不执行代码的。</p>
<figure><img src="/images/GPU_work_about_branches.png">
</figure>

<h4 id="divergent-与-convergent" class="headerLink">
    <a href="#divergent-%e4%b8%8e-convergent" class="header-mark"></a>Divergent 与 Convergent</h4><p>简单地说，如果分支条件是 VALU 产生的 (e.g. <code>v_cmp_eq_i32</code>)，那么这个分支被称为
<strong>divergent</strong>。此时只有一部分线程可以进入该分支，这一部分线程被称为 <strong>active</strong>，而那部分未进入的被称为 <strong>inactive</strong>。</p>
<p>通常，使用寄存器 EXEC 和 VCC 来进行跳转：<code>s_cbranch_execz</code> / <code>s_cbranch_vccnz</code> 等。
Vector 指令只会在 active 线程上执行，而 inactive 线程会忽略这些指令。对于 Scalar
指令，由于它是整个 wave 共享的，因此可以被认为是总是执行的。</p>
<p>在 SpirV 中有一个非常重要的概念 &ndash; Merge。这意味着，分支结构在 Merge Block 中发生 Convergent。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-glsl" data-lang="glsl"><span class="line"><span class="cl"><span class="c1">// EXEC = 0xF0F0</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="p">(</span><span class="n">divergentCond</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// EXEC = 0xF000</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// EXEC = 0x00F0</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="c1">// EXEC = 0xF0F0</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>另一种分支是由 SALU (e.g. <code>s_cmp_eq_i32</code>) 产生的，通常被写入状态寄存器的 SCC
(Scalar Condition Code) 中，用于整个 subgroup 的跳转，一般情况下这时并不会出现
EXEC 的变化。</p>
<h4 id="waterfall-loop" class="headerLink">
    <a href="#waterfall-loop" class="header-mark"></a>Waterfall Loop</h4><p>Waterfall loop 是一种特殊的循环结构，它通常由编译器产生，用于将特定 Vector 数据提升为 Scalar 数据，相同数据的线程同时执行，不同数据的线程依次执行。典型应用是
Vulkan 的 <a href="https://github.com/KhronosGroup/Vulkan-Samples/tree/main/samples/extensions/descriptor_indexing" target="_blank" rel="noopener noreferrer">NonuniformEXT</a>。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">// V0 holds the index value per lane
</span></span><span class="line"><span class="cl">// save exec mask for restore at the end
</span></span><span class="line"><span class="cl">s_mov_b64 s2, exec
</span></span><span class="line"><span class="cl">// exec mask of remaining (unprocessed) threads
</span></span><span class="line"><span class="cl">s_mov_b64 s4, exec
</span></span><span class="line"><span class="cl">loop:
</span></span><span class="line"><span class="cl">// get the index value for the first active lane
</span></span><span class="line"><span class="cl">v_readfirstlane_b32 s0, v0
</span></span><span class="line"><span class="cl">// find all other lanes with same index value
</span></span><span class="line"><span class="cl">v_cmpx_eq s0, v0
</span></span><span class="line"><span class="cl">&lt;OP&gt; // do the operation using the current EXEC mask. S0 holds the index.
</span></span><span class="line"><span class="cl">// mask out thread that was just executed
</span></span><span class="line"><span class="cl">s_andn2_wrexec_b64 s4, s4
</span></span><span class="line"><span class="cl">// repeat until EXEC==0
</span></span><span class="line"><span class="cl">s_cbranch_scc1 loop
</span></span><span class="line"><span class="cl">s_mov_b64 exec, s2
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="线性控制流" class="headerLink">
    <a href="#%e7%ba%bf%e6%80%a7%e6%8e%a7%e5%88%b6%e6%b5%81" class="header-mark"></a>线性控制流</h4><ul>
<li><a href="https://hal.science/hal-04171474v1/file/OASIcs-WCET-2023-1.pdf" target="_blank" rel="noopener noreferrer">Warp-Level CFG Construction for GPU Kernel WCET Analysis</a></li>
</ul>
<p>由于 GPU 的特性，实际上代码在 GPU 上类似于线性执行，因此在编译后期 (backend) 通常会加入线性控制流 (Linear Control Flow)来表示 BB 关系。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-llvm" data-lang="llvm"><span class="line"><span class="cl"><span class="nl">.entry:</span>
</span></span><span class="line"><span class="cl">  <span class="k">br</span> <span class="k">i1</span> <span class="nv">%cond</span><span class="p">,</span> <span class="kt">label</span> <span class="nv">%.then</span><span class="p">,</span> <span class="kt">label</span> <span class="nv">%.else</span>
</span></span><span class="line"><span class="cl"><span class="nl">.then:</span>
</span></span><span class="line"><span class="cl">  <span class="c">; do something
</span></span></span><span class="line"><span class="cl"><span class="c"></span>  <span class="k">br</span> <span class="kt">label</span> <span class="nv">%.endif</span>
</span></span><span class="line"><span class="cl"><span class="nl">.else:</span>
</span></span><span class="line"><span class="cl">  <span class="c">; do something
</span></span></span><span class="line"><span class="cl"><span class="c"></span>  <span class="k">br</span> <span class="kt">label</span> <span class="nv">%.endif</span>
</span></span><span class="line"><span class="cl"><span class="nl">.endif:</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>不同于 CPU 上要么执行 <code>.then</code> 分支要么执行 <code>.else</code> 分支，GPU 上实际是一部分线程先执行 <code>.then</code> 而另一部分线程再执行 <code>.else</code>。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-llvm" data-lang="llvm"><span class="line"><span class="cl"><span class="nl">.entry:</span>
</span></span><span class="line"><span class="cl">  <span class="n">%0</span> <span class="p">=</span> <span class="err">save_exe</span><span class="k">c</span>
</span></span><span class="line"><span class="cl">  <span class="k">br</span> <span class="kt">label</span> <span class="nv">%.then</span>
</span></span><span class="line"><span class="cl"><span class="nl">.then:</span>
</span></span><span class="line"><span class="cl">  <span class="nv">%exec</span> <span class="p">=</span> <span class="k">and</span> <span class="k">i32</span> <span class="nv">%exec</span><span class="p">,</span> <span class="nv">%vcc</span>
</span></span><span class="line"><span class="cl">  <span class="c">; do something
</span></span></span><span class="line"><span class="cl"><span class="c"></span>  <span class="k">br</span> <span class="kt">label</span> <span class="nv">%.else</span>
</span></span><span class="line"><span class="cl"><span class="nl">.else:</span>
</span></span><span class="line"><span class="cl">  <span class="nv">%exec</span> <span class="p">=</span> <span class="err">andn</span><span class="m">2</span> <span class="k">i32</span> <span class="n">%0</span><span class="p">,</span> <span class="nv">%exec</span>
</span></span><span class="line"><span class="cl">  <span class="c">; do something
</span></span></span><span class="line"><span class="cl"><span class="c"></span>  <span class="k">br</span> <span class="kt">label</span> <span class="nv">%.endif</span>
</span></span><span class="line"><span class="cl"><span class="nl">.endif:</span>
</span></span><span class="line"><span class="cl">  <span class="nv">%exec</span> <span class="p">=</span> <span class="n">%0</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="共享内存" class="headerLink">
    <a href="#%e5%85%b1%e4%ba%ab%e5%86%85%e5%ad%98" class="header-mark"></a>共享内存</h3><p><strong>shared memory</strong>，或称为 LDS (Local Data Share)。通常这是 Compute Shader 中的声明为
<em>shared</em> 的全局变量，或者 CUDA 中的 shared memory。该类型变量可以在一个 workgroup
中共享，即 shared 变量的修改可被在同一 workgroup 中的所有线程观察到。</p>
<figure><img src="/images/AMDGPU_RDNA3_Shared_Memory.png">
</figure>

<p>LDS 是一个大小为 128 KiB，由 2 个 CU 共享的片上 (On-Chip) 高速内存。分配大小为
1024 字节，配置为 64 个 bank。需要特别注意的是，在 CU Mode 下，实际上 LDS 是按照高低两部分平均分配给 2 个 CU 的，因此每部分的总大小 / bank / 分配大小等是配置一半，且 2 个 CU <strong>无法访问</strong>对方的 LDS。</p>
<p>而 GDS (Global Data Share) 是由整个 GPU 所有单元共享非片上 (Off-Chip) 4 KiB 内存，通常其被用于同步 (e.g. GS Stream)。</p>
<h3 id="缓存" class="headerLink">
    <a href="#%e7%bc%93%e5%ad%98" class="header-mark"></a>缓存</h3><ul>
<li><a href="https://en.algorithmica.org/hpc/cpu-cache/associativity/" target="_blank" rel="noopener noreferrer">Cache Associativity</a></li>
</ul>
<h4 id="分级缓存" class="headerLink">
    <a href="#%e5%88%86%e7%ba%a7%e7%bc%93%e5%ad%98" class="header-mark"></a>分级缓存</h4><p>Cache 通常被认为是程序不可见的，但在计算机体系结构中 Cache 起到了相当重要的作用。由于越靠近 ALU，存储单元速度越快，但由于价格与芯片面积的限制，这类存储单元也不会过于巨大。因此 On-Chip 多级缓存的概念应运而生：</p>
<figure><img src="/images/AMDGPU_RDNA3_Architecture_CacheSystem.jpg">
</figure>

<table>
<thead>
<tr>
<th>Kind</th>
<th>Size</th>
<th>Cache Line Size</th>
<th>Readable</th>
</tr>
</thead>
<tbody>
<tr>
<td>Instruction Cache</td>
<td>32 KiB per WGP</td>
<td>64 Bytes</td>
<td>RO</td>
</tr>
<tr>
<td>Scalar/K Data Cache</td>
<td>16 KiB per WGP</td>
<td>64 Bytes</td>
<td>RO</td>
</tr>
<tr>
<td>L0 Cache</td>
<td>2x32 KiB per WGP</td>
<td>2x128 Bytes</td>
<td>RO</td>
</tr>
<tr>
<td>L1 Cache</td>
<td>256 KiB per SA</td>
<td>64 Bytes (?)</td>
<td>RO</td>
</tr>
<tr>
<td>L2 Cache</td>
<td>6 MiB 16-way set-associative</td>
<td>64 Bytes (?)</td>
<td>RW</td>
</tr>
</tbody>
</table>
<h4 id="访存优化" class="headerLink">
    <a href="#%e8%ae%bf%e5%ad%98%e4%bc%98%e5%8c%96" class="header-mark"></a>访存优化</h4><p>当进行访存操作时，逐级访问 Cache，直到向内存发送访存请求。加载数据时，总是读取一个 Cache Line 的数据大小，即我们常说的<strong>局部性</strong>原理。当再次访问该地址附近的内存时，只需要从 Cache 中加载到寄存器，而不需要再进行漫长的访存等待，因此编译器倾向于将地址相近的访存指令排列在一起。</p>
<p>对于存储的数据进行优化也可能会影响性能，其主要是由于 Bank Conflict 以及 GPU 的访存特性引起的。因此上层应用也会在某些时候对内存数据布局进行优化。如 Graphics 中的
Texture swizzle lyaout 以及 <a href="https://stackoverflow.com/questions/44280335/how-much-faster-is-nchw-compared-to-nhwc-in-tensorflow-cudnn" target="_blank" rel="noopener noreferrer">CNN 中的 NCHW</a>。</p>
<figure><img src="/images/GPU_texture_swizzle_layout.png">
</figure>

<p>另外，当访存发生时，GPU 会发生 subgroup 级别的上下文切换，这类似于 CPU 上的阻塞进程切换。</p>
<figure><img src="/images/GPUOpen-AMDGPU-occupancy_explained-images-latency_hiding.png">
</figure>

<p>因此，编译器也会尽量将访存指令进行组合，以减少预期的上下文切换，且对性能有巨大的潜在提升。该优化在 LLVM 中被称为 <strong>GPU Load &amp; Store Vectorizer</strong>
(<code>lib/Transforms/Vectorize/LoadStoreVectorizer.cpp</code>)。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-llvm" data-lang="llvm"><span class="line"><span class="cl"><span class="c">; before
</span></span></span><span class="line"><span class="cl"><span class="c"></span><span class="n">%0</span> <span class="p">=</span> <span class="k">load</span> <span class="p">&lt;</span><span class="m">2</span> <span class="k">x</span> <span class="k">i32</span><span class="p">&gt;,</span> <span class="err">ptr</span> <span class="n">%1</span><span class="p">,</span> <span class="k">i32</span> <span class="m">0</span>
</span></span><span class="line"><span class="cl"><span class="n">%1</span> <span class="p">=</span> <span class="k">load</span> <span class="p">&lt;</span><span class="m">2</span> <span class="k">x</span> <span class="k">i32</span><span class="p">&gt;,</span> <span class="err">ptr</span> <span class="n">%1</span><span class="p">,</span> <span class="k">i32</span> <span class="m">64</span>
</span></span><span class="line"><span class="cl"><span class="c">; after
</span></span></span><span class="line"><span class="cl"><span class="c"></span><span class="n">%0</span> <span class="p">=</span> <span class="k">load</span> <span class="p">&lt;</span><span class="m">4</span> <span class="k">x</span> <span class="k">i32</span><span class="p">&gt;,</span> <span class="err">ptr</span> <span class="n">%1</span><span class="p">,</span> <span class="k">i32</span> <span class="m">0</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>当面对多条无法向量化的访存指令，无法避免地会有多次上下文切换。RDNA 架构引入 Hard
Clause 后，backend 也倾向于将访存指令组合 (Group) 起来，插入 <code>s_clause</code> 显式告诉
HW 将有多少条连续的同类型访存指令。该指令可以带来缓存一致性以及上下文切换的好处。
(<code>lib/Target/AMDGPU/SIInsertHardClauses.cpp</code>)</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="cl"><span class="n">s_clause</span> <span class="mh">0x1</span>
</span></span><span class="line"><span class="cl"><span class="n">buffer_load_b128</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">v0</span><span class="p">,</span> <span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="n">offset</span><span class="p">:</span><span class="mh">0x100</span>
</span></span><span class="line"><span class="cl"><span class="n">buffer_load_b128</span> <span class="n">v</span><span class="p">[</span><span class="mi">4</span><span class="p">:</span><span class="mi">7</span><span class="p">],</span> <span class="n">v8</span><span class="p">,</span> <span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="n">offset</span><span class="p">:</span><span class="mh">0xA00</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="缓存控制" class="headerLink">
    <a href="#%e7%bc%93%e5%ad%98%e6%8e%a7%e5%88%b6" class="header-mark"></a>缓存控制</h4><p>高级语言 (HLL, HighLevel Language) 中并不能感知到 Cache，但在高性能计算 (HPC,
High Performance Computing) 领域，人们总是会考虑 Cache 的存在，利用局部性与避免
Bank Conflict 的方法提高程序性能。</p>
<p>对于编译器来说，我们有对访存指令控制缓存的方法：</p>
<dl>
<dt>GLC</dt>
<dd>控制图形第一级缓存</dd>
<dt>SLC</dt>
<dd>控制 L2 缓存</dd>
</dl>
<p>DLC
:</p>
<p>这些控制位通常在 <strong>Memory Model</strong> 中非常有用。</p>
<h2 id="体系结构" class="headerLink">
    <a href="#%e4%bd%93%e7%b3%bb%e7%bb%93%e6%9e%84" class="header-mark"></a>体系结构</h2><h3 id="指令流水线--instruction-pipelining" class="headerLink">
    <a href="#%e6%8c%87%e4%bb%a4%e6%b5%81%e6%b0%b4%e7%ba%bf--instruction-pipelining" class="header-mark"></a>指令流水线 (Instruction Pipelining)</h3><p>在现代 CPU 体系结构中，指令流水线是非常重要的结构，其中可能有多达十多级流水线，以提供高性能运算。最为经典的是 5 级流水线：</p>
<ol>
<li>IF (Instruction Fetch) 指令读取</li>
<li>ID (Instruction decode and register fetch) 指令译码与寄存器读取</li>
<li>EX (Execute) 执行</li>
<li>MEM (Memory Access) 访存</li>
<li>WB (Register write back) 写回寄存器</li>
</ol>
<figure><img src="/images/InstructionPipelining-5_Stage_Pipeline.png">
</figure>

<h3 id="数据冒险" class="headerLink">
    <a href="#%e6%95%b0%e6%8d%ae%e5%86%92%e9%99%a9" class="header-mark"></a>数据冒险</h3><p>当表现出数据依赖性的指令修改流水线不同阶段中的数据时，就会发生<strong>数据冒险</strong> (Data
hazards)。忽略潜在的数据冒险可能会导致竞争条件。在三种情况下可能会发生数据冒险：</p>
<ul>
<li>写后读 (RAW, read after write) &ndash; <strong>true dependency</strong></li>
<li>读后写 (WAR, write after read) &ndash; <strong>anti dependency</strong></li>
<li>写后写 (WAW, write after write) &ndash; <strong>output dependency</strong></li>
<li>读后读 (RAR, read after read) &ndash; <strong>false dependency</strong>，该情况不会发生数据冒险</li>
</ul>
<p>假设有以下指令序列：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">v0 = add v1, v2
</span></span><span class="line"><span class="cl">v2 = mul v0, v3
</span></span><span class="line"><span class="cl">; cycles  0   1   2   3   4   5   6   7   8
</span></span><span class="line"><span class="cl">; add     IF  ID  EX  MEM WB
</span></span><span class="line"><span class="cl">; mul         NOP NOP NOP IF ID  EX  MEM WB
</span></span></code></pre></td></tr></table>
</div>
</div><p>上述示例是一则典型的 RAW，编译器必须保证数据写回 v0 后，才可以让下一条指令读取数据。</p>
<p>流水线冒泡 (Pipeline bubbling) 是通常处理数据冒险的方式，即发送空指令 (NOP) 来推迟数据依赖性指令的执行，从而保证数据的安全。因此编译器后端中 ISched (Instruction
Schedule, 指令重排) 显得尤为重要，Sched 应该尽可能将非依赖性指令重排在一起，以保证流水线的满载。</p>
<h3 id="sopp-指令" class="headerLink">
    <a href="#sopp-%e6%8c%87%e4%bb%a4" class="header-mark"></a>SOPP 指令</h3><p>在 AMDGPU 上，解决数据冒险的方式主要由一系列延迟性指令解决 &ndash; SOPP。SOPP 通常在
ISched 之后由后端插入。</p>
<p>当所有依赖关系满足时，SOPP 指令可能不会执行，或者说可以延迟 0 周期。</p>
<h4 id="s-delay-alu" class="headerLink">
    <a href="#s-delay-alu" class="header-mark"></a>S_DELAY_ALU</h4><p>在 SALU 和 VALU 依赖性指令之间插入延迟。该指令可以一次性显式指示两个 VALU 的数据依赖关系：</p>
<dl>
<dt>INSTID0</dt>
<dd>下一条 VALU 指令依赖的指令</dd>
<dt>INSTSKIP</dt>
<dd>跳过不需要延迟的 VALU 指令数量</dd>
<dt>INSTID1</dt>
<dd>第二条 VALU 指令的数据依赖关系</dd>
</dl>
<p>以 vkcube 为例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">v_fmac_f32_e32 v6, s20, v1                                  ; 560c0214
</span></span><span class="line"><span class="cl">v_fmac_f32_e32 v7, s21, v1                                  ; 560e0215
</span></span><span class="line"><span class="cl">v_fmac_f32_e32 v8, s22, v1                                  ; 56100216
</span></span><span class="line"><span class="cl">v_fmac_f32_e32 v3, s23, v1                                  ; 56060217
</span></span><span class="line"><span class="cl">s_delay_alu instid0(VALU_DEP_4) | instskip(SKIP_3) | instid1(VALU_DEP_3) ; bf8701c4
</span></span><span class="line"><span class="cl">; instid0: depends on v6
</span></span><span class="line"><span class="cl">v_fmac_f32_e32 v6, s24, v0                                  ; 560c0018
</span></span><span class="line"><span class="cl">; skip 3
</span></span><span class="line"><span class="cl">v_fmac_f32_e32 v7, s25, v0                                  ; 560e0019
</span></span><span class="line"><span class="cl">v_fmac_f32_e32 v8, s26, v0                                  ; 5610001a
</span></span><span class="line"><span class="cl">v_fmac_f32_e32 v3, s27, v0                                  ; 5606001b
</span></span><span class="line"><span class="cl">; instid1: depends on v7
</span></span><span class="line"><span class="cl">v_mov_b32_e32 v1, v7                                        ; 7e020307
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">s_add_u32 s0, s3, 7                                         ; 80008703
</span></span><span class="line"><span class="cl">s_delay_alu instid0(SALU_CYCLE_1) | instskip(NEXT) | instid1(SALU_CYCLE_1) ; bf870499
</span></span><span class="line"><span class="cl">; instid0: depends on s0
</span></span><span class="line"><span class="cl">s_and_b32 s0, s0, -8                                        ; 8b00c800
</span></span><span class="line"><span class="cl">; instid1: depends on s0
</span></span><span class="line"><span class="cl">s_pack_ll_b32_b16 s0, 0, s0                                 ; 99000080
</span></span><span class="line"><span class="cl">s_delay_alu instid0(SALU_CYCLE_1)                           ; bf870009
</span></span><span class="line"><span class="cl">; instid0: depends on s0
</span></span><span class="line"><span class="cl">s_bfe_u64 exec, -1, s0                                      ; 947e00c1
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="s-waitcnt" class="headerLink">
    <a href="#s-waitcnt" class="header-mark"></a>S_WAITCNT</h4><p>waitcnt 系列指令用于延迟等待事件或访存。它们依赖于对应的指令计数器，当计数器等于或低于指定的值时，程序继续向下执行。</p>
<ul>
<li>VMcnt: Texture SAMPLE、VMemory Load 及 VMemory atomic-with-return</li>
<li>VScnt: VMemory Store</li>
<li>LGKMcnt:
<ul>
<li>LDS indexed operations</li>
<li>SMemory</li>
<li>GDS &amp; GWS</li>
<li>FLAT instructions (uses both LGKMcnt and either VMcnt or VScnt)</li>
<li>Message</li>
</ul>
</li>
<li>EXPcnt
<ul>
<li>LDS parameter-load and direct-load</li>
<li>Exports</li>
</ul>
</li>
</ul>
<!--listend-->
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="cl"><span class="p">;</span> <span class="n">VMcnt</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">VScnt</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">LGKMcnt</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl"><span class="n">s_load_b128</span> <span class="n">s</span><span class="p">[</span><span class="mi">12</span><span class="p">:</span><span class="mi">15</span><span class="p">],</span> <span class="n">s</span><span class="p">[</span><span class="mi">10</span><span class="p">:</span><span class="mi">11</span><span class="p">],</span> <span class="n">null</span>                        <span class="p">;</span> <span class="n">f4080305</span> <span class="n">f8000000</span>
</span></span><span class="line"><span class="cl"><span class="p">;</span> <span class="n">VMcnt</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">VScnt</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">LGKMcnt</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl"><span class="n">s_waitcnt</span> <span class="n">lgkmcnt</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>                                        <span class="p">;</span> <span class="n">bf89fc07</span>
</span></span><span class="line"><span class="cl"><span class="p">;</span> <span class="n">VMcnt</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">VScnt</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">LGKMcnt</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl"><span class="n">buffer_load_b128</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">v5</span><span class="p">,</span> <span class="n">s</span><span class="p">[</span><span class="mi">12</span><span class="p">:</span><span class="mi">15</span><span class="p">],</span> <span class="mi">0</span> <span class="n">offen</span> <span class="n">offset</span><span class="p">:</span><span class="mi">64</span>    <span class="p">;</span> <span class="n">e05c0040</span> <span class="mi">80430005</span>
</span></span><span class="line"><span class="cl"><span class="p">;</span> <span class="n">VMcnt</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">VScnt</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">LGKMcnt</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl"><span class="n">s_buffer_load_b128</span> <span class="n">s</span><span class="p">[</span><span class="mi">8</span><span class="p">:</span><span class="mi">11</span><span class="p">],</span> <span class="n">s</span><span class="p">[</span><span class="mi">12</span><span class="p">:</span><span class="mi">15</span><span class="p">],</span> <span class="mh">0x30</span>                  <span class="p">;</span> <span class="n">f4280206</span> <span class="n">f8000030</span>
</span></span><span class="line"><span class="cl"><span class="p">;</span> <span class="n">VMcnt</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">VScnt</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">LGKMcnt</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl"><span class="n">s_buffer_load_b128</span> <span class="n">s</span><span class="p">[</span><span class="mi">16</span><span class="p">:</span><span class="mi">19</span><span class="p">],</span> <span class="n">s</span><span class="p">[</span><span class="mi">12</span><span class="p">:</span><span class="mi">15</span><span class="p">],</span> <span class="mh">0x20</span>                 <span class="p">;</span> <span class="n">f4280406</span> <span class="n">f8000020</span>
</span></span><span class="line"><span class="cl"><span class="p">;</span> <span class="n">VMcnt</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">VScnt</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">LGKMcnt</span> <span class="o">=</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl"><span class="n">s_buffer_load_b128</span> <span class="n">s</span><span class="p">[</span><span class="mi">20</span><span class="p">:</span><span class="mi">23</span><span class="p">],</span> <span class="n">s</span><span class="p">[</span><span class="mi">12</span><span class="p">:</span><span class="mi">15</span><span class="p">],</span> <span class="mh">0x10</span>                 <span class="p">;</span> <span class="n">f4280506</span> <span class="n">f8000010</span>
</span></span><span class="line"><span class="cl"><span class="p">;</span> <span class="n">VMcnt</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">VScnt</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">LGKMcnt</span> <span class="o">=</span> <span class="mi">3</span>
</span></span><span class="line"><span class="cl"><span class="n">s_buffer_load_b128</span> <span class="n">s</span><span class="p">[</span><span class="mi">24</span><span class="p">:</span><span class="mi">27</span><span class="p">],</span> <span class="n">s</span><span class="p">[</span><span class="mi">12</span><span class="p">:</span><span class="mi">15</span><span class="p">],</span> <span class="n">null</span>                 <span class="p">;</span> <span class="n">f4280606</span> <span class="n">f8000000</span>
</span></span><span class="line"><span class="cl"><span class="p">;</span> <span class="n">VMcnt</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">VScnt</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">LGKMcnt</span> <span class="o">=</span> <span class="mi">4</span>
</span></span><span class="line"><span class="cl"><span class="n">buffer_load_b64</span> <span class="n">v</span><span class="p">[</span><span class="mi">4</span><span class="p">:</span><span class="mi">5</span><span class="p">],</span> <span class="n">v5</span><span class="p">,</span> <span class="n">s</span><span class="p">[</span><span class="mi">12</span><span class="p">:</span><span class="mi">15</span><span class="p">],</span> <span class="mi">0</span> <span class="n">offen</span> <span class="n">offset</span><span class="p">:</span><span class="mi">640</span>    <span class="p">;</span> <span class="n">e0540280</span> <span class="mi">80430405</span>
</span></span><span class="line"><span class="cl"><span class="p">;</span> <span class="n">VMcnt</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">VScnt</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">LGKMcnt</span> <span class="o">=</span> <span class="mi">4</span>
</span></span><span class="line"><span class="cl"><span class="n">s_waitcnt</span> <span class="n">vmcnt</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="n">lgkmcnt</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>                               <span class="p">;</span> <span class="n">bf890407</span>
</span></span><span class="line"><span class="cl"><span class="p">;</span> <span class="n">VMcnt</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">VScnt</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">LGKMcnt</span> <span class="o">=</span> <span class="mi">0</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="mi">4</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span> <span class="n">may</span> <span class="ow">not</span> <span class="k">return</span>
</span></span><span class="line"><span class="cl"><span class="n">v_mul_f32_e32</span> <span class="n">v6</span><span class="p">,</span> <span class="n">s8</span><span class="p">,</span> <span class="n">v3</span>                                    <span class="p">;</span> <span class="mi">100</span><span class="n">c0608</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="分支预测" class="headerLink">
    <a href="#%e5%88%86%e6%94%af%e9%a2%84%e6%b5%8b" class="header-mark"></a>分支预测</h3><p>分支处理能力是现代 CPU 的强项，其主要贡献是<strong>分支预测</strong>技术。简单地说，这是一项为了填满流水线而提前将分支中的指令载入流水线的操作。分支预测的准确性通常能达到 <code>90%</code>
以上。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-llvm" data-lang="llvm"><span class="line"><span class="cl">  <span class="k">br</span> <span class="k">i1</span> <span class="nv">%cond</span><span class="p">,</span> <span class="kt">label</span> <span class="nv">%.then</span><span class="p">,</span> <span class="kt">label</span> <span class="nv">%.endif</span>
</span></span><span class="line"><span class="cl"><span class="nl">.then:</span>
</span></span><span class="line"><span class="cl">  <span class="c">; do somethings
</span></span></span><span class="line"><span class="cl"><span class="c"></span>  <span class="k">br</span> <span class="kt">label</span> <span class="nv">%.endif</span>
</span></span><span class="line"><span class="cl"><span class="nl">.endif:</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>如此分支，当执行到跳转指令时，CPU 不得不停下流水线等待运算结果，来确定接下来执行的指令序列。当加入分支预测功能后，CPU 会尝试预测一个极有可能进入的分支，并在跳转指令还未完成时，直接将该分支中的指令开始解析并执行。</p>
<p>如果分支预测正确，那么 CPU 将不受 pipeline bubbling 的影响，可以高效执行分支。如果预测失败，CPU 必须将现有流水线全部清空，再重新开始执行分支，这通常需要付出极大的代价。我们也将预测失败称为 <strong>控制冒险</strong> (Control/Branch hazard)。</p>
<p>为了避免控制冒险，可以在分支条件之后插入流水线冒泡以保证足够的延迟，从而避免清空流水线。</p>
<h3 id="指令预取" class="headerLink">
    <a href="#%e6%8c%87%e4%bb%a4%e9%a2%84%e5%8f%96" class="header-mark"></a>指令预取</h3><p>在现代计算机体系架构中，指令作为一种特殊的数据进行读取。在 .elf 文件中，指令被存储在只读的 <code>.text</code> 段中。PC (Program Counter) 用于指明下一个需要执行的指令。</p>
<p>指令预取可以提前将当前 PC 之前的一部分指令存储到 ICache 中，通常可以是 1 / 2 / 3
个 ICache Line 的大小 (共 64 / 128 / 192 Bytes)。该值可以通过 subgroup 的状态寄存器设置，或在程序中使用 <code>S_SET_INST_PREFETCH_DISTANCE</code> 显式设置。</p>
<p>由于指令预取的存在，且防止在程序即将结束时预取出的指令无效，AMDGPU spec 推荐使用
256 Bytes 的 <code>S_CODE_END</code> 来填充程序。</p>
<h2 id="gpgpu--general-purpose-computing-on-graphics-processing-units" class="headerLink">
    <a href="#gpgpu--general-purpose-computing-on-graphics-processing-units" class="header-mark"></a>GPGPU (General-purpose computing on graphics processing units)</h2><ul>
<li>Compute Shader on Vulkan / OpenGL / D3D</li>
<li>OpenMP / OpenACC</li>
<li>OpenCL / SYCL / CUDA / RCOm / OneAPI</li>
</ul>
<h3 id="workgroup-与-subgroup" class="headerLink">
    <a href="#workgroup-%e4%b8%8e-subgroup" class="header-mark"></a>Workgroup 与 Subgroup</h3><p>工作组 (workgroup) 是 compute shader 中的概念，由 <code>local_size_(x|y|z)</code> 声明该
workgroup 的大小。在 AMDGPU 上，一个 workgroup 最多可以有 1024 个线程，即 1 个
CU。如 Compute shader 可以一次性派发 (Dispatch) 多个 workgroup，即
<code>glDispatchCompute</code>。</p>
<h4 id="线程标识" class="headerLink">
    <a href="#%e7%ba%bf%e7%a8%8b%e6%a0%87%e8%af%86" class="header-mark"></a>线程标识</h4><p>对于 workgroup 和线程编号，有以下定义：</p>
<ul>
<li><code>const uvec3 gl_WorkGroupSize</code>: 用于存储当前 workgroup 的大小，即程序中指定的
<code>local_size_(x|y|z)</code>。</li>
<li><code>in uvec3 gl_LocalInvocationID</code>: 工作组内的每个线程的三维索引，范围在 <code>uvec3(0)</code>
和 <code>gl_WorkGroupSize - uvec3(1)</code> 之间。</li>
<li><code>in uvec3 gl_NumWorkGroups</code>: 由 <code>glDispatchCompute</code> 产生的全局工作组数量，三个
channel 分别是该函数的参数。</li>
<li><code>in uvec3 gl_WorkGroupID</code>: 工作组在全局范围内的三维索引，范围在 <code>uvec3(0)</code> 和
<code>gl_NumWorkGroups - uvec3(1)</code> 之间。</li>
<li><code>in uvec3 gl_GlobalInvocationID</code>: 表示当前线程在全局工作组中的一个唯一三维索引，可以通过  \(gl\_WorkGroupID * gl\_WorkGroupSize +
gl\_LocalInvocationID\) 计算而来。</li>
<li><code>in uint gl_LocalInvocationIndex</code>: 表示当前线程在全局工作组中的一个扁平化的一维索引。可以通过以下表达式计算得出：
\[\begin{aligned}
gl\_WorkGroupSize.x \times gl\_LocalInvocationID.x + &amp; \\
gl\_WorkGroupSize.y \times gl\_LocalInvocationID.y + &amp; \\
gl\_WorkGroupSize.z \times gl\_LocalInvocationID.z &amp;
\end{aligned}\]</li>
</ul>
<p>之前提到过，subgroup 就是硬件所能控制的最小线程束，因此它等价于 AMDGPU 的
wavefront。在 Navi3 上，wavefront 支持 wave32 和 wave64，因此查询 vulkan info 可以看到其 subgroup size 的定义为：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">minSubgroupSize = 32
</span></span><span class="line"><span class="cl">maxSubgroupSize = 64
</span></span></code></pre></td></tr></table>
</div>
</div><p>在程序中，我们可以使用以下相关变量：</p>
<ul>
<li><code>in uint gl_SubgroupSize</code>: 总是和 API 设置的 subgroup size 相同，也就是说，用户可以在 AMDGPU 上自行选择 subgroup 的大小。</li>
<li><code>in uint gl_SubgroupInvocationID</code>: 在一个 subgroup 内线程的 ID。范围总是在
\(\left[0, subgroupSize\right)\)。</li>
<li><code>in uint gl_NumSubgroups</code>: 在一个 workgroup 内有多少个 subgroup。这个值取决于
workgroup 的大小，且最少是 <strong>1</strong>。简单地计算方式为 \(\lfloor
(workgroupSize+subgroupSize-1)/subgroupSize \rfloor\)。</li>
<li><code>in uint gl_SubgroupID</code>: workgroup 内每个 subgroup 的唯一编号。范围
\(\left[0,numSubgroups\right)\)。</li>
</ul>
<h4 id="线程标识的实现" class="headerLink">
    <a href="#%e7%ba%bf%e7%a8%8b%e6%a0%87%e8%af%86%e7%9a%84%e5%ae%9e%e7%8e%b0" class="header-mark"></a>线程标识的实现</h4><p>在 HW 启动程序时会初始化一些基本状态：</p>
<table>
<thead>
<tr>
<th>寄存器</th>
<th>值</th>
</tr>
</thead>
<tbody>
<tr>
<td>s0~s15</td>
<td>User data</td>
</tr>
<tr>
<td>then</td>
<td>WorkGroupID.x</td>
</tr>
<tr>
<td>then</td>
<td>WorkGroupID.y</td>
</tr>
<tr>
<td>then</td>
<td>WorkGroupID.z</td>
</tr>
<tr>
<td>then</td>
<td>MultiDispatchInfo</td>
</tr>
<tr>
<td>v0</td>
<td>LocalInvocationIndex.x (10bit)</td>
</tr>
</tbody>
</table>
<p>另外在计算 <code>SubgroupInvocationID</code> 时通常使用该组指令：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">; EXEC = 0xFFFFFFFF / 0xFFFFFFFFFFFFFFFF
</span></span><span class="line"><span class="cl">v_mbcnt_lo_u32_b32 v0, -1, 0
</span></span><span class="line"><span class="cl">v_mbcnt_hi_u32_b32 v0, -1, v0 ; if SubgroupSize is 64
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="subgroup-操作" class="headerLink">
    <a href="#subgroup-%e6%93%8d%e4%bd%9c" class="header-mark"></a>Subgroup 操作</h4><ul>
<li><a href="https://www.khronos.org/blog/vulkan-subgroup-tutorial" target="_blank" rel="noopener noreferrer">Vulkan Subgroup Tutorial</a></li>
<li><a href="https://www.khronos.org/assets/uploads/developers/library/2018-vulkan-devday/06-subgroups.pdf" target="_blank" rel="noopener noreferrer">Vulkan Subgroup Explained</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/469436345" target="_blank" rel="noopener noreferrer">现代图形 API 的 Wave Intrinsics、Subgroup 以及 SIMD-group</a></li>
</ul>
<h3 id="内存模型" class="headerLink">
    <a href="#%e5%86%85%e5%ad%98%e6%a8%a1%e5%9e%8b" class="header-mark"></a>内存模型</h3><p>内存模型描述了线程通过内存的交互以及它们对数据的共享使用，因此这在 CS 中极为重要，同时也是现代通用编程语言的多线程基础。并以此衍生出了 Memory ordering、Memory
barrier、Atomic 等概念。</p>
<p>推荐阅读：</p>
<ul>
<li><a href="https://research.swtch.com/mm" target="_blank" rel="noopener noreferrer">Memory Models</a> 系列文章</li>
<li><a href="https://en.cppreference.com/w/cpp/atomic/memory_order" target="_blank" rel="noopener noreferrer">std::memory_order</a></li>
<li><a href="https://llvm.org/docs/LangRef.html#memory-model-for-concurrent-operations" target="_blank" rel="noopener noreferrer">LLVM Language Reference Manual - Memory Model for Concurrent Operations</a></li>
<li><a href="https://llvm.org/docs/Atomics.html" target="_blank" rel="noopener noreferrer">LLVM &ndash; LLVM Atomic Instructions and Concurrency Guide</a></li>
</ul>
<h3 id="ieee-754" class="headerLink">
    <a href="#ieee-754" class="header-mark"></a>IEEE 754</h3><ul>
<li><a href="https://matloka.com/blog/floating-point-101" target="_blank" rel="noopener noreferrer">Floating-point arithmetic – all you need to know, explained interactively</a></li>
</ul>
<h4 id="浮点数的表示" class="headerLink">
    <a href="#%e6%b5%ae%e7%82%b9%e6%95%b0%e7%9a%84%e8%a1%a8%e7%a4%ba" class="header-mark"></a>浮点数的表示</h4><p>以单精度浮点数 (float) 为例，其以 1 bit 符号位 (S)，8 bit 指数位 (E) 以及 23 bit
尾数位 (F) 构成。</p>
<table>
<thead>
<tr>
<th>类别</th>
<th>符号位</th>
<th>指数位</th>
<th>实际表示的指数</th>
<th>尾数位</th>
<th>数值</th>
<th>二进制表示</th>
</tr>
</thead>
<tbody>
<tr>
<td>零</td>
<td>0</td>
<td>0x00</td>
<td>-127</td>
<td>0x000000</td>
<td>0.0</td>
<td>0x00000000</td>
</tr>
<tr>
<td>负零</td>
<td>1</td>
<td>0x00</td>
<td>-127</td>
<td>0x000000</td>
<td>-0.0</td>
<td>0x80000000</td>
</tr>
<tr>
<td>一</td>
<td>0</td>
<td>0x7F</td>
<td>0</td>
<td>0x000000</td>
<td>1.0</td>
<td>0x3F800000</td>
</tr>
<tr>
<td>负一</td>
<td>1</td>
<td>0x7F</td>
<td>0</td>
<td>0x000000</td>
<td>-1.0</td>
<td>0xBF800000</td>
</tr>
<tr>
<td>Normal</td>
<td>*</td>
<td>0x01 ~ 0xFE</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>最小的 Normal</td>
<td>*</td>
<td>0x01</td>
<td>-126</td>
<td>0x000000</td>
<td>\(2^{1-127}\)</td>
<td>0x00800000</td>
</tr>
<tr>
<td>最大的 Normal</td>
<td>*</td>
<td>0xFE</td>
<td>127</td>
<td>0x7FFFFF</td>
<td>\(\num{3.4e38}\)</td>
<td>0x7F7FFFFF</td>
</tr>
<tr>
<td>Denormal</td>
<td>*</td>
<td>0x00</td>
<td>-126</td>
<td>非零</td>
<td></td>
<td></td>
</tr>
<tr>
<td>最小的 Denormal</td>
<td>*</td>
<td>0x00</td>
<td>-126</td>
<td>0x000001</td>
<td>\(\num{1.4e-45}\)</td>
<td>0x00000001</td>
</tr>
<tr>
<td>最大的 Denormal</td>
<td>*</td>
<td>0x00</td>
<td>-126</td>
<td>0x7FFFFF</td>
<td>\(\num{1.18e-38}\)</td>
<td>0x007FFFFF</td>
</tr>
<tr>
<td>正无穷</td>
<td>0</td>
<td>0xFF</td>
<td>128</td>
<td>0x000000</td>
<td>\(+\infty\)</td>
<td>0x7F800000</td>
</tr>
<tr>
<td>负无穷</td>
<td>1</td>
<td>0xFF</td>
<td>128</td>
<td>0x000000</td>
<td>\(-\infty\)</td>
<td>0xFF800000</td>
</tr>
<tr>
<td>NaN</td>
<td>*</td>
<td>0xFF</td>
<td>128</td>
<td>非零</td>
<td>NaN</td>
<td></td>
</tr>
<tr>
<td>signaling NaN</td>
<td>*</td>
<td>0xFF</td>
<td>128</td>
<td>0x000001 ~ 0x3FFFFF</td>
<td></td>
<td>0x7FBFFFFF</td>
</tr>
<tr>
<td>quiet NaN</td>
<td>*</td>
<td>0xFF</td>
<td>128</td>
<td>0x400000 ~ 0x7FFFFF</td>
<td></td>
<td>0x7FFFFFFF</td>
</tr>
</tbody>
</table>
<h4 id="精度" class="headerLink">
    <a href="#%e7%b2%be%e5%ba%a6" class="header-mark"></a>精度</h4><p>浮点数的精度通常使用 ULP (Unit in the last place) 表示，简单地说就是浮点数在保留指数位时，其最低有效位为 1 时所表示的值。比如说 1.0 (<code>0x3f800000</code>)，其 ULP(1.0) 表示为 <code>float(0x3f800001)-1.0</code>。</p>
<p>比如说 Navi31XTX 上，<code>V_ADD_F32</code> 的精度是 0.5 ULP，<code>V_EXP_F32</code> 的精度是 1.0 ULP。</p>
<h4 id="float-control" class="headerLink">
    <a href="#float-control" class="header-mark"></a>Float Control</h4><ul>
<li><a href="https://htmlpreview.github.io/?https://github.com/KhronosGroup/SPIRV-Registry/blob/main/extensions/KHR/SPV_KHR_float_controls.html" target="_blank" rel="noopener noreferrer">SPV_KHR_float_controls</a></li>
<li><a href="https://htmlpreview.github.io/?https://github.com/KhronosGroup/SPIRV-Registry/blob/main/extensions/KHR/SPV_KHR_float_controls2.html" target="_blank" rel="noopener noreferrer">SPV_KHR_float_controls2</a></li>
<li><a href="https://en.cppreference.com/w/cpp/numeric/fenv" target="_blank" rel="noopener noreferrer">C++ Floating-point environment</a></li>
</ul>
<h2 id="compiler" class="headerLink">
    <a href="#compiler" class="header-mark"></a>Compiler</h2></div>

        <div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 09-01</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"><span><a class="link-to-mardown" href=/2023/gpu-introduce/index.md target="_blank" rel="noopener noreferrer">阅读原始文档</a>
                    </span><span>|&nbsp;<a class="link-to-report" href=https://gitlab.com/GinShio/ginshio.gitlab.io/issues/new?issue[title]=[BUG]%20GPU+%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D&issue[description]=[POST](https://blog.ginshio.org/2023/gpu-introduce/)%0A%0A##%20Isseus%0A target="_blank" rel="noopener noreferrer">报告问题</a>
                    </span></div>
            <div class="post-info-share">
                <span><a href="#" title="分享到 Twitter" data-sharer="twitter" data-url="https://blog.ginshio.org/2023/gpu-introduce/" data-title="GPU 基础介绍" data-hashtags="Introduce,AMD"><i class="fab fa-twitter fa-fw"></i></a><a href="#" title="分享到 Facebook" data-sharer="facebook" data-url="https://blog.ginshio.org/2023/gpu-introduce/" data-hashtag="Introduce"><i class="fab fa-facebook-square fa-fw"></i></a><a href="#" title="分享到 Linkedin" data-sharer="linkedin" data-url="https://blog.ginshio.org/2023/gpu-introduce/"><i class="fab fa-linkedin fa-fw"></i></a><a href="#" title="分享到 WhatsApp" data-sharer="whatsapp" data-url="https://blog.ginshio.org/2023/gpu-introduce/" data-title="GPU 基础介绍" data-web><i class="fab fa-whatsapp fa-fw"></i></a><a href="#" title="分享到 Hacker News" data-sharer="hackernews" data-url="https://blog.ginshio.org/2023/gpu-introduce/" data-title="GPU 基础介绍"><i class="fab fa-hacker-news fa-fw"></i></a><a href="#" title="分享到 Line" data-sharer="line" data-url="https://blog.ginshio.org/2023/gpu-introduce/" data-title="GPU 基础介绍"><i data-svg-src="/lib/simple-icons/icons/line.min.svg"></i></a><a href="#" title="分享到 Telegram" data-sharer="telegram" data-url="https://blog.ginshio.org/2023/gpu-introduce/" data-title="GPU 基础介绍" data-web><i class="fab fa-telegram-plane fa-fw"></i></a><a href="#" class="weixin" title="分享到 微信" data-sharer="weixin" data-url="https://blog.ginshio.org/2023/gpu-introduce/" data-title="GPU 基础介绍" data-web><i class="fab fa-weixin fa-fw"></i><img src="https://api.oick.cn/qrcode/api.php?size=256&amp;text=https://blog.ginshio.org/2023/gpu-introduce/" title="GPU 基础介绍">
    </a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/introduce/">Introduce</a>,&nbsp;<a href="/tags/amd/">AMD</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/2023/how-to-build-mesa/" class="prev" rel="prev" title="How To Build Mesa for AMD"><i class="fas fa-angle-left fa-fw"></i>How To Build Mesa for AMD</a>
            <a href="/2024/how-to-use-deqp-runner/" class="next" rel="next" title="How To Use Mesa&#39;s test tool: deqp-runner">How To Use Mesa&#39;s test tool: deqp-runner<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id="comments"><div id="gitalk" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://github.com/gitalk/gitalk"></a>Gitalk</a>.
            </noscript></div></article></div>
        </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">
                    由 <a href="https://gohugo.io/" target="_blank" rel="noopener noreferrer" title="Hugo 0.131.0">Hugo</a> 强力驱动&nbsp;|&nbsp;主题 - <a href="https://github.com/HEIGE-PCloud/DoIt" target="_blank" rel="noopener noreferrer" title="DoIt 0.3.0"><i class="far fa-edit fa-fw"></i> DoIt</a>
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2020 - 2024</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="https://blog.ginshio.org/" target="_blank" rel="noopener noreferrer">GinShio</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
            <div class="footer-line"></div>
            <div class="footer-line">
            </div>
        </div><script>
                    if('serviceWorker' in navigator) {
                        navigator.serviceWorker
                            .register('/sw.min.js', { scope: '/' })
                            .then(function(registration) {
                            });
                
                        navigator.serviceWorker
                            .ready
                            .then(function(registration) {
                            });
                    }
                </script></footer></div>

    <div id="fixed-buttons"><a href="#back-to-top" id="back-to-top-button" class="fixed-button" title="回到顶部">
            <i class="fas fa-arrow-up fa-fw"></i>
        </a><a href="#" id="view-comments" class="fixed-button" title="查看评论">
            <i class="fas fa-comment fa-fw"></i>
        </a>
    </div><div class="assets"><link rel="stylesheet" href="/lib/gitalk/gitalk.min.b82a526943533d0dde3eceea68e6d3879e8f766339a17d2c57bbde5421167ddeafa4734202e9950c16842cc6d27753b4.css" integrity="sha384-uCpSaUNTPQ3ePs7qaObTh56PdmM5oX0sV7veVCEWfd6vpHNCAumVDBaELMbSd1O0"><link rel="stylesheet" href="/lib/katex/katex.min.bcaaee8fe6b5dd4f321c8900c8680ad49dc0ad32f3ac51816c1734b43a7869dfc4c9ec0449e5c4fc8bfaec08fc80a674.css" integrity="sha384-vKruj&#43;a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0"><link rel="preload" as="style" onload="this.onload=null;this.rel='stylesheet'" href="/lib/katex/copy-tex.min.1f5388069d157848068f2228e33a72016ef3233cfb0afc2940343e446a708357e5b391b470f94c0e1c80745c331651ca.css" integrity="sha384-H1OIBp0VeEgGjyIo4zpyAW7zIzz7CvwpQDQ&#43;RGpwg1fls5G0cPlMDhyAdFwzFlHK">
        <noscript><link rel="stylesheet" href="/lib/katex/copy-tex.min.1f5388069d157848068f2228e33a72016ef3233cfb0afc2940343e446a708357e5b391b470f94c0e1c80745c331651ca.css" integrity="sha384-H1OIBp0VeEgGjyIo4zpyAW7zIzz7CvwpQDQ&#43;RGpwg1fls5G0cPlMDhyAdFwzFlHK"></noscript><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":12},"comment":{"gitalk":{"admin":["GinShio"],"clientID":"96cbbb15f26bebd9141b","clientSecret":"29c7df99d6e1806113996333163a9476027ff1fa","id":"2023-08-28T22:25:22+08:00","owner":"GinShio","repo":"ginshio.github.io","title":"GPU 基础介绍"}},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"ABF13CGNA0","algoliaIndex":"ginshio_blog","algoliaSearchKey":"51cf3425aba132c091b477c3d5e06eea","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"},"sharerjs":true,"table":{"sort":true}};</script><script type="text/javascript" src="/lib/gitalk/gitalk.min.1420a0c0459673bc6824e7ba713f1e0ec1540e86491daf1b6149a7af9cd3f396c86b9182d03e4c727faefae17b746033.js" integrity="sha384-FCCgwEWWc7xoJOe6cT8eDsFUDoZJHa8bYUmnr5zT85bIa5GC0D5Mcn&#43;u&#43;uF7dGAz"></script><script type="text/javascript" src="/js/gitalk.min.js" defer></script><script type="text/javascript" src="/lib/tablesort/tablesort.min.d120034e53740430f5243f8e25b646e7bdcca97780e02962c37e3adefb264c1b457f8fc397698851f42e32d7168bdd1e.js" integrity="sha384-0SADTlN0BDD1JD&#43;OJbZG573MqXeA4Cliw3463vsmTBtFf4/Dl2mIUfQuMtcWi90e"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.094758c1816ef1698123c876e7b739ac27751905f428bfb349857a93244d636b615bb42a43298a19f4c2235587c33bf2.js" integrity="sha384-CUdYwYFu8WmBI8h257c5rCd1GQX0KL&#43;zSYV6kyRNY2thW7QqQymKGfTCI1WHwzvy"></script><script type="text/javascript" src="/lib/sharer/sharer.min.0097b33812ac4873e9a2e0813de400c9ea9b07e223998d3cbc38a89bdfa3f45cc344689061a836fcd6f4c120eed429b4.js" integrity="sha384-AJezOBKsSHPpouCBPeQAyeqbB&#43;IjmY08vDiom9&#43;j9FzDRGiQYag2/Nb0wSDu1Cm0"></script><script type="text/javascript" src="/lib/katex/katex.min.3f04544ff62a6e71239193b4cd9c4da9cc400ab5defa3efae94d9a997720320e78e7baef7b663b23a6494a6d80d264b8.js" integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe&#43;j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" defer></script><script type="text/javascript" src="/lib/katex/auto-render.min.f95071777afa5e0511c9caad675d7b9d8c38e0e39c21ac79e99e1d09159bc723edd0aa1a875b87a0ad28e3efd1444d39.js" integrity="sha384-&#43;VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4&#43;/RRE05" defer></script><script type="text/javascript" src="/lib/katex/copy-tex.min.c30ff9f376878715a4cf90c4567e8e2ad36221a2e2da20513595df251898d408bbb6727d517a44b32bce2135694e5e00.js" integrity="sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A" defer></script><script type="text/javascript" src="/lib/katex/mhchem.min.453374f1ad005c88a83c1715a2c12a3d47ca2beacfa7e875c7f8b347bc4c91d332bb091c64259dc4ef914b0205b495cd.js" integrity="sha384-RTN08a0AXIioPBcVosEqPUfKK&#43;rPp&#43;h1x/izR7xMkdMyuwkcZCWdxO&#43;RSwIFtJXN" defer></script><script type="text/javascript" src="/js/katex.min.js" defer></script><script type="text/javascript" src="/js/theme.min.js" defer></script><script type="text/javascript">
            window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());
            gtag('config', 'G-J5NHMZLLDX', { 'anonymize_ip': true });
        </script><script type="text/javascript" src="https://www.googletagmanager.com/gtag/js?id=G-J5NHMZLLDX" async></script><script>
			var _hmt = _hmt || [];
			(function() {
			  var hm = document.createElement("script");
			  hm.src = "https://hm.baidu.com/hm.js?9370523af547bac6b97e9c3b1461cd16";
			  var s = document.getElementsByTagName("script")[0]; 
			  s.parentNode.insertBefore(hm, s);
			})();
		</script></div>
</body>

</html>